{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sanity Check.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWmUA50y9ASX",
        "outputId": "16801aa8-8ccd-4817-a66a-986b3ad4d600"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "### Drive Access\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Importing the necessary libraries\n",
        "import warnings\n",
        "import sys\n",
        "import io\n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "from matplotlib import pyplot\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.linear_model import Lasso,Ridge\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "from collections import *\n",
        "from math import sqrt,ceil,log2,floor,pi\n",
        "from datetime import datetime\n",
        "from copy import deepcopy\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "### Reading the csv file\n",
        "np.random.seed(0)\n",
        "notebookpath = \"/content/drive/MyDrive/Colab Notebooks/SanityCheck.csv\"\n",
        "df = pd.read_csv(notebookpath)\n",
        "#df"
      ],
      "metadata": {
        "id": "D77wM95x9LgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Preprocessing for MLR\n",
        "df1 = deepcopy(df)\n",
        "df1 = df1.drop(columns = ['Symbol','Series','Volume','VWAP','Deliverable Volume','%Deliverble'], axis = 1)\n",
        "lastcol = len(df1.columns)\n",
        "dfnum = df1[df1.columns[list(range(2,lastcol))]]\n",
        "cols = list(dfnum.columns)\n",
        "meantrades = df1['Trades'].mean()\n",
        "df1['Trades'].fillna(value=meantrades, inplace=True)\n",
        "data1 = pd.DataFrame(df1, columns = cols)\n",
        "targetfeature = 'Close'\n",
        "\n",
        "### Preprocessing for LSTM\n",
        "df2 = deepcopy(df)\n",
        "meantrades = df2['Trades'].mean()\n",
        "df2['Trades'].fillna(value=meantrades, inplace=True)\n",
        "df2 = df2.drop(columns = ['Symbol','Series','Volume','VWAP','Deliverable Volume','%Deliverble'], axis = 1)\n",
        "lastcol = len(df2.columns)\n",
        "dfstr = df2[df2.columns[list(range(0,2))]]\n",
        "dfnum = df2[df2.columns[list(range(2,lastcol))]]\n",
        "scaler = MinMaxScaler()\n",
        "cols = list(dfnum.columns)\n",
        "dfnum = scaler.fit_transform(dfnum)\n",
        "smin = scaler.data_min_\n",
        "smax = scaler.data_max_\n",
        "dfnum = pd.DataFrame(dfnum, columns = cols)\n",
        "dfscaled = pd.concat([dfstr , dfnum], axis = 1, join = 'inner')\n",
        "dfscaled = dfnum\n",
        "data2 = deepcopy(dfscaled)\n",
        "\n",
        "### Preprocessing for ElasticNet\n",
        "df3 = deepcopy(df)\n",
        "meantrades = df3['Trades'].mean()\n",
        "df3['Trades'].fillna(value=meantrades, inplace=True)\n",
        "df3 = df3.drop(columns = ['Symbol','Series'], axis = 1)\n",
        "lastcol = len(df3.columns)\n",
        "dfstr = df3[df3.columns[list(range(0,2))]]\n",
        "dfnum = df3[df3.columns[list(range(2,lastcol))]]\n",
        "cols = list(dfnum.columns)\n",
        "dfnum = pd.DataFrame(dfnum, columns = cols)  \n",
        "dfscaled = pd.concat([dfstr , dfnum], axis = 1, join = 'inner')\n",
        "dfscaled = dfnum\n",
        "data3 = deepcopy(dfscaled)\n",
        "\n",
        "### Preprocessing for CNN\n",
        "df4 = deepcopy(df)\n",
        "meantrades = df4['Trades'].mean()\n",
        "df4['Trades'].fillna(value=meantrades, inplace=True)\n",
        "df4 = df4.drop(columns = ['Symbol','Series','Volume','VWAP','Deliverable Volume','%Deliverble'], axis = 1)\n",
        "data4 = deepcopy(df4)"
      ],
      "metadata": {
        "id": "5Gg9swJT_PI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Window Size is 5\n",
        "\n",
        "### MLR + Ridge\n",
        "window = 5\n",
        "\n",
        "j = 0;\n",
        "def transform(dfscaled, win):\n",
        "  df2 = deepcopy(dfscaled)\n",
        "  col = df2.columns\n",
        "  for i in range(2, win+1):\n",
        "    for c in col:\n",
        "      df2[c+str(i)] = df2[c].shift(-(i-1)) #stepback i-1 times\n",
        "      df2['Close'+str(win+1)] = df2['Close'].shift(-(win)) #stepback i-1 times\n",
        "  return df2\n",
        "print(\"window\"+str(window))\n",
        "data = transform(data1, window)\n",
        "scaler = MinMaxScaler()\n",
        "data1 = scaler.fit_transform(data)\n",
        "data1 = pd.DataFrame(data1)\n",
        "   \n",
        "MLR = pickle.load(open('MLR_Ridge_5.pkl', 'rb'))\n",
        "trainn = deepcopy(data.loc[0:10])\n",
        "testt = deepcopy(data.loc[10:15])\n",
        "trainnY = trainn[\"Close\"+str(window+1)].values\n",
        "del trainn[\"Close\"+str(window+1)]\n",
        "trainn.drop(columns=[])\n",
        "trainnX = trainn.values.astype(np.float64)\n",
        "testtY = testt[\"Close\"+str(window+1)].values\n",
        "del testt[\"Close\"+str(window+1)]\n",
        "testtX = testt.values.astype(np.float64) \n",
        "testp = MLR.predict(testtX)\n",
        "print(testp)\n",
        "print(mean_squared_error(testp, testtY))"
      ],
      "metadata": {
        "id": "c3xGu4jZBuBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Window Size is 5\n",
        "\n",
        "### LSTM\n",
        "window = [5]\n",
        "\n",
        "def transdata(dfscaled, win):\n",
        "  df2 = deepcopy(dfscaled)\n",
        "  col = df2.columns\n",
        "  for i in range(2, win+1):\n",
        "    for c in col:\n",
        "      df2[c+str(i)] = df2[c].shift(-(i-1)) #stepback i-1 times\n",
        "  \n",
        "  df2['Close'+str(win+1)] = df2['Close'].shift(-(win)) #stepback i-1 times\n",
        "  return df2\n",
        "\n",
        "data = transdata(data2, 5)\n",
        "LSTM = pickle.load(open('model.pkl', 'rb'))\n",
        "trainn = deepcopy(data.loc[0:10])\n",
        "testt = deepcopy(data.loc[10:15])\n",
        "trainnY = trainn[\"Close\"+str(window+1)].values\n",
        "del trainn[\"Close\"+str(window+1)]\n",
        "trainn.drop(columns=[])\n",
        "trainnX = trainn.values.astype(np.float64)\n",
        "testtY = testt[\"Close\"+str(window+1)].values\n",
        "del testt[\"Close\"+str(window+1)]\n",
        "testtX = testt.values.astype(np.float64) \n",
        "testp = LSTM.predict(testtX)\n",
        "print(mean_squared_error(testp, testtY))"
      ],
      "metadata": {
        "id": "NM5tl0SuDaUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Window Size is 5\n",
        "\n",
        "### Elastic Net\n",
        "window = [5]\n",
        "\n",
        "def transdata(dfscaled, win):\n",
        "  df2 = deepcopy(dfscaled)\n",
        "  col = df2.columns\n",
        "  for i in range(2, win+1):\n",
        "    for c in col:\n",
        "      df2[c+str(i)] = df2[c].shift(-(i-1)) #stepback i-1 times\n",
        "  \n",
        "  df2['Close'+str(win+1)] = df2['Close'].shift(-(win)) #stepback i-1 times\n",
        "  return df2\n",
        "\n",
        "data = transdata(data3, 5)\n",
        "ENR = pickle.load(open('model.pkl', 'rb'))\n",
        "trainn = deepcopy(data.loc[0:10])\n",
        "testt = deepcopy(data.loc[10:15])\n",
        "trainnY = trainn[\"Close\"+str(window+1)].values\n",
        "del trainn[\"Close\"+str(window+1)]\n",
        "trainn.drop(columns=[])\n",
        "trainnX = trainn.values.astype(np.float64)\n",
        "testtY = testt[\"Close\"+str(window+1)].values\n",
        "del testt[\"Close\"+str(window+1)]\n",
        "testtX = testt.values.astype(np.float64) \n",
        "testp = ENR.predict(testtX)\n",
        "print(mean_squared_error(testp, testtY))"
      ],
      "metadata": {
        "id": "mxZQnGZlEzTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Window Size is 5\n",
        "\n",
        "### CNN\n",
        "def split_sequence(sequence, n_steps):\n",
        "  X, y = list(), list()\n",
        "\tfor i in range(len(sequence)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_steps\n",
        "\t\t# check if we are beyond the sequence\n",
        "\t\tif end_ix > len(sequence)-1:\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn array(X), array(y)\n",
        "closing_univariate_data = list(data4[\"Close\"])\n",
        "n_steps = 5\n",
        "X, y = split_sequence(closing_univariate_data, n_steps)\n",
        "n_features = 1\n",
        "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
        "CNN = pickle.load(open('model.pkl', 'rb'))\n",
        "X_train,y_train = X[0:10],y[0:10]\n",
        "X_test,y_test = X[10:15],y[10:15]\n",
        "testp = ENR.predict(X_test)\n",
        "print(mean_squared_error(testp, Y_test))"
      ],
      "metadata": {
        "id": "wv1vQibAFGp4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}